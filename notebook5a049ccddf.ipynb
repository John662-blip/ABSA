{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3009440,"sourceType":"datasetVersion","datasetId":1822081}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:28.064215Z","iopub.execute_input":"2025-09-18T12:30:28.064461Z","iopub.status.idle":"2025-09-18T12:30:28.340312Z","shell.execute_reply.started":"2025-09-18T12:30:28.064439Z","shell.execute_reply":"2025-09-18T12:30:28.339548Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptop_Train_v2.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Restaurants_Test_Data_PhaseB.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/laptops-trial.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseB.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/restaurants-trial.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/SemEvalSchema.xsd\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_phaseB.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseA.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseA.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Restaurants_Train_v2.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/laptops-trial.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Restaurants_Train_v2.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Restaurants_Test_Data_phaseB.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Restaurants_Test_Data_PhaseA.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Restaurants_Test_Data_PhaseA.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Restaurants_Train.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptop_Train_v2.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/restaurants-trial.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\n# Duyệt qua tất cả các file trong thư mục /kaggle/input\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if 'laptop' in filename.lower():  \n            print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:28.341456Z","iopub.execute_input":"2025-09-18T12:30:28.341820Z","iopub.status.idle":"2025-09-18T12:30:28.347900Z","shell.execute_reply.started":"2025-09-18T12:30:28.341792Z","shell.execute_reply":"2025-09-18T12:30:28.347229Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptop_Train_v2.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/laptops-trial.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseB.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_phaseB.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseA.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseA.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/laptops-trial.xml\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptop_Train_v2.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if 'laptop' in filename.lower():  \n            if 'csv' in filename:\n                print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:28.348580Z","iopub.execute_input":"2025-09-18T12:30:28.348844Z","iopub.status.idle":"2025-09-18T12:30:28.361633Z","shell.execute_reply.started":"2025-09-18T12:30:28.348820Z","shell.execute_reply":"2025-09-18T12:30:28.361082Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/laptops-trial.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseB.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptops_Test_Data_PhaseA.csv\n/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptop_Train_v2.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv('/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptop_Train_v2.csv')\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:28.363195Z","iopub.execute_input":"2025-09-18T12:30:28.363574Z","iopub.status.idle":"2025-09-18T12:30:28.421156Z","shell.execute_reply.started":"2025-09-18T12:30:28.363558Z","shell.execute_reply":"2025-09-18T12:30:28.420614Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        id                                           Sentence  \\\n0     2339  I charge it at night and skip taking the cord ...   \n1     2339  I charge it at night and skip taking the cord ...   \n2     1316  The tech guy then said the service center does...   \n3     1316  The tech guy then said the service center does...   \n4     1316  The tech guy then said the service center does...   \n...    ...                                                ...   \n2353  2272  We also use Paralles so we can run virtual mac...   \n2354  2272  We also use Paralles so we can run virtual mac...   \n2355   848  How Toshiba handles the repair seems to vary, ...   \n2356   848  How Toshiba handles the repair seems to vary, ...   \n2357   734  I would like to use a different operating syst...   \n\n                         Aspect Term  polarity  from   to  \n0                               cord   neutral    41   45  \n1                       battery life  positive    74   86  \n2                     service center  negative    27   41  \n3                       \"sales\" team  negative   109  121  \n4                           tech guy   neutral     4   12  \n...                              ...       ...   ...  ...  \n2353  Windows Server Enterprise 2003   neutral   104  134  \n2354  Windows Server 2008 Enterprise   neutral   140  170  \n2355                          repair  conflict    24   30  \n2356                          repair  positive   130  136  \n2357                operating system   neutral    32   48  \n\n[2358 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Sentence</th>\n      <th>Aspect Term</th>\n      <th>polarity</th>\n      <th>from</th>\n      <th>to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>neutral</td>\n      <td>41</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>positive</td>\n      <td>74</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>negative</td>\n      <td>27</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>\"sales\" team</td>\n      <td>negative</td>\n      <td>109</td>\n      <td>121</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>neutral</td>\n      <td>4</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2353</th>\n      <td>2272</td>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>Windows Server Enterprise 2003</td>\n      <td>neutral</td>\n      <td>104</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>2354</th>\n      <td>2272</td>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>Windows Server 2008 Enterprise</td>\n      <td>neutral</td>\n      <td>140</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>2355</th>\n      <td>848</td>\n      <td>How Toshiba handles the repair seems to vary, ...</td>\n      <td>repair</td>\n      <td>conflict</td>\n      <td>24</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2356</th>\n      <td>848</td>\n      <td>How Toshiba handles the repair seems to vary, ...</td>\n      <td>repair</td>\n      <td>positive</td>\n      <td>130</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>2357</th>\n      <td>734</td>\n      <td>I would like to use a different operating syst...</td>\n      <td>operating system</td>\n      <td>neutral</td>\n      <td>32</td>\n      <td>48</td>\n    </tr>\n  </tbody>\n</table>\n<p>2358 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Model phat hien","metadata":{}},{"cell_type":"markdown","source":"## Tiền Xử lí ","metadata":{}},{"cell_type":"code","source":"\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:28.421637Z","iopub.execute_input":"2025-09-18T12:30:28.421842Z","iopub.status.idle":"2025-09-18T12:30:54.301091Z","shell.execute_reply.started":"2025-09-18T12:30:28.421826Z","shell.execute_reply":"2025-09-18T12:30:54.300468Z"}},"outputs":[{"name":"stderr","text":"2025-09-18 12:30:41.455649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758198641.624701      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758198641.679535      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:54.301855Z","iopub.execute_input":"2025-09-18T12:30:54.302321Z","iopub.status.idle":"2025-09-18T12:30:54.306084Z","shell.execute_reply.started":"2025-09-18T12:30:54.302301Z","shell.execute_reply":"2025-09-18T12:30:54.305271Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom datasets import Dataset\ntokenizer_name=\"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\ndef df_to_hf_dataset(df, tokenizer):\n    \n    bio_data = []\n    grouped = df.groupby('id', sort=False)\n\n    for _, group in grouped:\n        sentence = group['Sentence'].iloc[0]\n        \n        aspects = [(int(row['from']), int(row['to'])) for _, row in group.iterrows()]\n        encoding = tokenizer(sentence, return_offsets_mapping=True, truncation=True)\n        tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n        offsets = encoding['offset_mapping']\n        labels = [0] * len(tokens)\n        for start, end in aspects:\n            for i, (s, e) in enumerate(offsets):\n                if e > start and s < end:  \n                    if s <= start:\n                        labels[i] = 1\n                    else:\n                        labels[i] = 2\n\n        bio_data.append({'tokens': tokens, 'labels': labels})\n    dataset = Dataset.from_list(bio_data)\n    return dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:54.306908Z","iopub.execute_input":"2025-09-18T12:30:54.307095Z","iopub.status.idle":"2025-09-18T12:30:55.730829Z","shell.execute_reply.started":"2025-09-18T12:30:54.307080Z","shell.execute_reply":"2025-09-18T12:30:55.730087Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5712d649bddd477fa4faeebaa15f374e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6180f7896ed49b8950a0ea17a2a1e59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae384d40534418c8fe660fe9d6d0a04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a484c826b34494bb8ac7513edea155c"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"dataset = df_to_hf_dataset(train_df,tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:55.731595Z","iopub.execute_input":"2025-09-18T12:30:55.731842Z","iopub.status.idle":"2025-09-18T12:30:56.346329Z","shell.execute_reply.started":"2025-09-18T12:30:55.731822Z","shell.execute_reply":"2025-09-18T12:30:56.345764Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.347057Z","iopub.execute_input":"2025-09-18T12:30:56.347267Z","iopub.status.idle":"2025-09-18T12:30:56.351475Z","shell.execute_reply.started":"2025-09-18T12:30:56.347250Z","shell.execute_reply":"2025-09-18T12:30:56.350962Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['tokens', 'labels'],\n    num_rows: 1488\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.353965Z","iopub.execute_input":"2025-09-18T12:30:56.354166Z","iopub.status.idle":"2025-09-18T12:30:56.368014Z","shell.execute_reply.started":"2025-09-18T12:30:56.354151Z","shell.execute_reply":"2025-09-18T12:30:56.367414Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        id                                           Sentence  \\\n0     2339  I charge it at night and skip taking the cord ...   \n1     2339  I charge it at night and skip taking the cord ...   \n2     1316  The tech guy then said the service center does...   \n3     1316  The tech guy then said the service center does...   \n4     1316  The tech guy then said the service center does...   \n...    ...                                                ...   \n2353  2272  We also use Paralles so we can run virtual mac...   \n2354  2272  We also use Paralles so we can run virtual mac...   \n2355   848  How Toshiba handles the repair seems to vary, ...   \n2356   848  How Toshiba handles the repair seems to vary, ...   \n2357   734  I would like to use a different operating syst...   \n\n                         Aspect Term  polarity  from   to  \n0                               cord   neutral    41   45  \n1                       battery life  positive    74   86  \n2                     service center  negative    27   41  \n3                       \"sales\" team  negative   109  121  \n4                           tech guy   neutral     4   12  \n...                              ...       ...   ...  ...  \n2353  Windows Server Enterprise 2003   neutral   104  134  \n2354  Windows Server 2008 Enterprise   neutral   140  170  \n2355                          repair  conflict    24   30  \n2356                          repair  positive   130  136  \n2357                operating system   neutral    32   48  \n\n[2358 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Sentence</th>\n      <th>Aspect Term</th>\n      <th>polarity</th>\n      <th>from</th>\n      <th>to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>neutral</td>\n      <td>41</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>positive</td>\n      <td>74</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>negative</td>\n      <td>27</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>\"sales\" team</td>\n      <td>negative</td>\n      <td>109</td>\n      <td>121</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>neutral</td>\n      <td>4</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2353</th>\n      <td>2272</td>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>Windows Server Enterprise 2003</td>\n      <td>neutral</td>\n      <td>104</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>2354</th>\n      <td>2272</td>\n      <td>We also use Paralles so we can run virtual mac...</td>\n      <td>Windows Server 2008 Enterprise</td>\n      <td>neutral</td>\n      <td>140</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>2355</th>\n      <td>848</td>\n      <td>How Toshiba handles the repair seems to vary, ...</td>\n      <td>repair</td>\n      <td>conflict</td>\n      <td>24</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2356</th>\n      <td>848</td>\n      <td>How Toshiba handles the repair seems to vary, ...</td>\n      <td>repair</td>\n      <td>positive</td>\n      <td>130</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>2357</th>\n      <td>734</td>\n      <td>I would like to use a different operating syst...</td>\n      <td>operating system</td>\n      <td>neutral</td>\n      <td>32</td>\n      <td>48</td>\n    </tr>\n  </tbody>\n</table>\n<p>2358 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_df['Sentence'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.368586Z","iopub.execute_input":"2025-09-18T12:30:56.368784Z","iopub.status.idle":"2025-09-18T12:30:56.380674Z","shell.execute_reply.started":"2025-09-18T12:30:56.368761Z","shell.execute_reply":"2025-09-18T12:30:56.380138Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'I charge it at night and skip taking the cord with me because of the good battery life.'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"print(dataset['tokens'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.381350Z","iopub.execute_input":"2025-09-18T12:30:56.381589Z","iopub.status.idle":"2025-09-18T12:30:56.428452Z","shell.execute_reply.started":"2025-09-18T12:30:56.381565Z","shell.execute_reply":"2025-09-18T12:30:56.427926Z"}},"outputs":[{"name":"stdout","text":"['[CLS]', 'i', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.', '[SEP]']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(dataset['labels'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.429020Z","iopub.execute_input":"2025-09-18T12:30:56.429210Z","iopub.status.idle":"2025-09-18T12:30:56.449100Z","shell.execute_reply.started":"2025-09-18T12:30:56.429196Z","shell.execute_reply":"2025-09-18T12:30:56.448447Z"}},"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.449752Z","iopub.execute_input":"2025-09-18T12:30:56.449998Z","iopub.status.idle":"2025-09-18T12:30:56.462087Z","shell.execute_reply.started":"2025-09-18T12:30:56.449981Z","shell.execute_reply":"2025-09-18T12:30:56.461388Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch\n\ndef prepare_dataset_for_bert(dataset, tokenizer):\n    input_ids_list = []\n    attention_mask_list = []\n    labels_list = []\n\n    for tokens, labels in zip(dataset['tokens'], dataset['labels']):\n        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n        attention_mask = [1] * len(input_ids)\n\n        label_ids = labels.copy()\n        # gán -100 cho [CLS] và [SEP]\n        label_ids[0] = -100\n        label_ids[-1] = -100\n\n       \n        input_ids_list.append(torch.tensor(input_ids))\n        attention_mask_list.append(torch.tensor(attention_mask))\n        labels_list.append(torch.tensor(label_ids))\n\n    return input_ids_list, attention_mask_list, labels_list\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.462728Z","iopub.execute_input":"2025-09-18T12:30:56.462957Z","iopub.status.idle":"2025-09-18T12:30:56.475200Z","shell.execute_reply.started":"2025-09-18T12:30:56.462934Z","shell.execute_reply":"2025-09-18T12:30:56.474573Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import AutoTokenizer\ninput_ids_list, attention_mask_list, labels_list = prepare_dataset_for_bert(dataset, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.475813Z","iopub.execute_input":"2025-09-18T12:30:56.476014Z","iopub.status.idle":"2025-09-18T12:30:56.591177Z","shell.execute_reply.started":"2025-09-18T12:30:56.475999Z","shell.execute_reply":"2025-09-18T12:30:56.590766Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(dataset['tokens'][0])\nprint(len(dataset['tokens'][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.591954Z","iopub.execute_input":"2025-09-18T12:30:56.592148Z","iopub.status.idle":"2025-09-18T12:30:56.659258Z","shell.execute_reply.started":"2025-09-18T12:30:56.592133Z","shell.execute_reply":"2025-09-18T12:30:56.658545Z"}},"outputs":[{"name":"stdout","text":"['[CLS]', 'i', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.', '[SEP]']\n21\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Kiểm tra\nprint(input_ids_list[0])\nprint(attention_mask_list[0])\nprint(labels_list[0])\n\nprint(len(input_ids_list[0]))\nprint(len(attention_mask_list[0]))\nprint(len(labels_list[0]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.659889Z","iopub.execute_input":"2025-09-18T12:30:56.660089Z","iopub.status.idle":"2025-09-18T12:30:56.680181Z","shell.execute_reply.started":"2025-09-18T12:30:56.660074Z","shell.execute_reply":"2025-09-18T12:30:56.679420Z"}},"outputs":[{"name":"stdout","text":"tensor([  101,  1045,  3715,  2009,  2012,  2305,  1998, 13558,  2635,  1996,\n        11601,  2007,  2033,  2138,  1997,  1996,  2204,  6046,  2166,  1012,\n          102])\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\ntensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n           0,    0,    0,    0,    0,    1,    2,    0, -100])\n21\n21\n21\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"hf_dataset = Dataset.from_dict({\n    'input_ids': input_ids_list,\n    'attention_mask': attention_mask_list,\n    'labels': labels_list\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.681009Z","iopub.execute_input":"2025-09-18T12:30:56.681254Z","iopub.status.idle":"2025-09-18T12:30:56.746841Z","shell.execute_reply.started":"2025-09-18T12:30:56.681230Z","shell.execute_reply":"2025-09-18T12:30:56.746373Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Tạo các tập","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom datasets import Dataset\ntokenizer_name=\"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(tokenizer_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:56.747416Z","iopub.execute_input":"2025-09-18T12:30:56.747625Z","iopub.status.idle":"2025-09-18T12:30:57.048293Z","shell.execute_reply.started":"2025-09-18T12:30:56.747610Z","shell.execute_reply":"2025-09-18T12:30:57.047549Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"path_train = \"/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/Laptop_Train_v2.csv\"\npath_test = \"/kaggle/input/semeval-2014-task-4-aspectbasedsentimentanalysis/laptops-trial.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.049412Z","iopub.execute_input":"2025-09-18T12:30:57.050145Z","iopub.status.idle":"2025-09-18T12:30:57.053280Z","shell.execute_reply.started":"2025-09-18T12:30:57.050118Z","shell.execute_reply":"2025-09-18T12:30:57.052609Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"df_train = pd.read_csv(path_train)\ndf_test = pd.read_csv(path_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.054017Z","iopub.execute_input":"2025-09-18T12:30:57.054194Z","iopub.status.idle":"2025-09-18T12:30:57.081913Z","shell.execute_reply.started":"2025-09-18T12:30:57.054180Z","shell.execute_reply":"2025-09-18T12:30:57.081409Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.082703Z","iopub.execute_input":"2025-09-18T12:30:57.082960Z","iopub.status.idle":"2025-09-18T12:30:57.090499Z","shell.execute_reply.started":"2025-09-18T12:30:57.082945Z","shell.execute_reply":"2025-09-18T12:30:57.089869Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"     id                                           Sentence     Aspect Term  \\\n0  2339  I charge it at night and skip taking the cord ...            cord   \n1  2339  I charge it at night and skip taking the cord ...    battery life   \n2  1316  The tech guy then said the service center does...  service center   \n3  1316  The tech guy then said the service center does...    \"sales\" team   \n4  1316  The tech guy then said the service center does...        tech guy   \n\n   polarity  from   to  \n0   neutral    41   45  \n1  positive    74   86  \n2  negative    27   41  \n3  negative   109  121  \n4   neutral     4   12  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Sentence</th>\n      <th>Aspect Term</th>\n      <th>polarity</th>\n      <th>from</th>\n      <th>to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>neutral</td>\n      <td>41</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>positive</td>\n      <td>74</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>negative</td>\n      <td>27</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>\"sales\" team</td>\n      <td>negative</td>\n      <td>109</td>\n      <td>121</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>neutral</td>\n      <td>4</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.091206Z","iopub.execute_input":"2025-09-18T12:30:57.091403Z","iopub.status.idle":"2025-09-18T12:30:57.107979Z","shell.execute_reply.started":"2025-09-18T12:30:57.091380Z","shell.execute_reply":"2025-09-18T12:30:57.107229Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"     id                                           Sentence    Aspect Term  \\\n0  2128                         I liked the aluminum body.  aluminum body   \n1    81           Lightweight and the screen is beautiful!         screen   \n2   353  From the build quality to the performance, eve...  build quality   \n3   353  From the build quality to the performance, eve...    performance   \n4   655  It was truly a great computer costing less tha...        costing   \n\n   polarity  from  to  \n0  positive    12  25  \n1  positive    20  26  \n2  negative     9  22  \n3  negative    30  41  \n4  positive    30  37  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Sentence</th>\n      <th>Aspect Term</th>\n      <th>polarity</th>\n      <th>from</th>\n      <th>to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2128</td>\n      <td>I liked the aluminum body.</td>\n      <td>aluminum body</td>\n      <td>positive</td>\n      <td>12</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>81</td>\n      <td>Lightweight and the screen is beautiful!</td>\n      <td>screen</td>\n      <td>positive</td>\n      <td>20</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>353</td>\n      <td>From the build quality to the performance, eve...</td>\n      <td>build quality</td>\n      <td>negative</td>\n      <td>9</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>353</td>\n      <td>From the build quality to the performance, eve...</td>\n      <td>performance</td>\n      <td>negative</td>\n      <td>30</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>655</td>\n      <td>It was truly a great computer costing less tha...</td>\n      <td>costing</td>\n      <td>positive</td>\n      <td>30</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"dataset_train = df_to_hf_dataset(df_train,tokenizer)\ninput_ids_list_train, attention_mask_list_train, labels_list_train = prepare_dataset_for_bert(dataset_train, tokenizer)\ntrain_datset = Dataset.from_dict({\n    'input_ids': input_ids_list_train,\n    'attention_mask': attention_mask_list_train,\n    'labels': labels_list_train\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.108606Z","iopub.execute_input":"2025-09-18T12:30:57.108823Z","iopub.status.idle":"2025-09-18T12:30:57.870919Z","shell.execute_reply.started":"2025-09-18T12:30:57.108807Z","shell.execute_reply":"2025-09-18T12:30:57.870395Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"dataset_test = df_to_hf_dataset(df_test,tokenizer)\ninput_ids_list_test, attention_mask_list_test, labels_list_test = prepare_dataset_for_bert(dataset_test, tokenizer)\ntest_datset = Dataset.from_dict({\n    'input_ids': input_ids_list_test,\n    'attention_mask': attention_mask_list_test,\n    'labels': labels_list_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.871600Z","iopub.execute_input":"2025-09-18T12:30:57.871845Z","iopub.status.idle":"2025-09-18T12:30:57.909978Z","shell.execute_reply.started":"2025-09-18T12:30:57.871828Z","shell.execute_reply":"2025-09-18T12:30:57.909296Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## lấy model ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.910758Z","iopub.execute_input":"2025-09-18T12:30:57.910984Z","iopub.status.idle":"2025-09-18T12:30:57.914393Z","shell.execute_reply.started":"2025-09-18T12:30:57.910968Z","shell.execute_reply":"2025-09-18T12:30:57.913890Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:30:57.919364Z","iopub.execute_input":"2025-09-18T12:30:57.919559Z","iopub.status.idle":"2025-09-18T12:31:00.496943Z","shell.execute_reply.started":"2025-09-18T12:30:57.919544Z","shell.execute_reply":"2025-09-18T12:31:00.496380Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81174b477b90473a8df9246f0bb5d46a"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:31:00.497631Z","iopub.execute_input":"2025-09-18T12:31:00.497859Z","iopub.status.idle":"2025-09-18T12:31:00.503555Z","shell.execute_reply.started":"2025-09-18T12:31:00.497841Z","shell.execute_reply":"2025-09-18T12:31:00.502912Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:31:00.504302Z","iopub.execute_input":"2025-09-18T12:31:00.504549Z","iopub.status.idle":"2025-09-18T12:31:00.525824Z","shell.execute_reply.started":"2025-09-18T12:31:00.504525Z","shell.execute_reply":"2025-09-18T12:31:00.525103Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"! pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:31:00.526607Z","iopub.execute_input":"2025-09-18T12:31:00.526815Z","iopub.status.idle":"2025-09-18T12:31:06.975631Z","shell.execute_reply.started":"2025-09-18T12:31:00.526799Z","shell.execute_reply":"2025-09-18T12:31:06.974893Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=90e1c151fd5699e4977f93b896cf0762f6106aaedd02afa5c4ee4c9edf96726e\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from seqeval.metrics import precision_score, recall_score, f1_score\nimport numpy as np\n\nid2label = {0:'O', 1:'B-ASP', 2:'I-ASP'}\ndef compute_metrics(p):\n    # p.predictions: (batch_size, seq_len, num_labels)\n    # p.label_ids: (batch_size, seq_len)\n    preds = np.argmax(p.predictions, axis=-1) # batch_size, seq_len\n    labels = p.label_ids\n\n    true_labels = []\n    true_preds = []\n\n    for pred_seq, label_seq in zip(preds, labels):\n        pred_labels = []\n        gold_labels = []\n        for p_lab, l_lab in zip(pred_seq, label_seq):\n            if l_lab == -100:\n                continue \n            pred_labels.append(id2label[p_lab])\n            gold_labels.append(id2label[l_lab])\n        true_preds.append(pred_labels)\n        true_labels.append(gold_labels)\n\n    precision = precision_score(true_labels, true_preds)\n    recall = recall_score(true_labels, true_preds)\n    f1 = f1_score(true_labels, true_preds)\n\n    return {\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:31:06.976847Z","iopub.execute_input":"2025-09-18T12:31:06.977156Z","iopub.status.idle":"2025-09-18T12:31:06.993354Z","shell.execute_reply.started":"2025-09-18T12:31:06.977119Z","shell.execute_reply":"2025-09-18T12:31:06.992621Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./bert_aspect_model\",\n    num_train_epochs=10,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100, \n    eval_steps=100,              \n    save_total_limit=2,\n    save_steps=100,\n    report_to=\"none\",\n    disable_tqdm=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:31:06.994149Z","iopub.execute_input":"2025-09-18T12:31:06.994343Z","iopub.status.idle":"2025-09-18T12:31:07.023449Z","shell.execute_reply.started":"2025-09-18T12:31:06.994328Z","shell.execute_reply":"2025-09-18T12:31:07.022771Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_datset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:31:07.024386Z","iopub.execute_input":"2025-09-18T12:31:07.024913Z","iopub.status.idle":"2025-09-18T12:31:07.350691Z","shell.execute_reply.started":"2025-09-18T12:31:07.024888Z","shell.execute_reply":"2025-09-18T12:31:07.349942Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:31:07.351612Z","iopub.execute_input":"2025-09-18T12:31:07.351867Z","iopub.status.idle":"2025-09-18T12:32:47.978601Z","shell.execute_reply.started":"2025-09-18T12:31:07.351849Z","shell.execute_reply":"2025-09-18T12:32:47.977713Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 01:39, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.147000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.019100</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.006200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.002500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=470, training_loss=0.037465677711557836, metrics={'train_runtime': 100.1352, 'train_samples_per_second': 148.599, 'train_steps_per_second': 4.694, 'total_flos': 433846359284832.0, 'train_loss': 0.037465677711557836, 'epoch': 10.0})"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"trainer.evaluate(eval_dataset=train_datset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:47.979459Z","iopub.execute_input":"2025-09-18T12:32:47.979795Z","iopub.status.idle":"2025-09-18T12:32:50.724370Z","shell.execute_reply.started":"2025-09-18T12:32:47.979765Z","shell.execute_reply":"2025-09-18T12:32:50.723562Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='49' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [47/47 00:02]\n    </div>\n    "},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.0004915378522127867,\n 'eval_precision': 0.9995759117896522,\n 'eval_recall': 0.9995759117896522,\n 'eval_f1': 0.9995759117896522,\n 'eval_runtime': 2.7344,\n 'eval_samples_per_second': 544.188,\n 'eval_steps_per_second': 17.189,\n 'epoch': 10.0}"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trainer.evaluate(eval_dataset=test_datset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:50.725209Z","iopub.execute_input":"2025-09-18T12:32:50.725390Z","iopub.status.idle":"2025-09-18T12:32:50.802642Z","shell.execute_reply.started":"2025-09-18T12:32:50.725375Z","shell.execute_reply":"2025-09-18T12:32:50.801894Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.07412030547857285,\n 'eval_precision': 0.9215686274509803,\n 'eval_recall': 0.9591836734693877,\n 'eval_f1': 0.9400000000000001,\n 'eval_runtime': 0.0669,\n 'eval_samples_per_second': 597.745,\n 'eval_steps_per_second': 29.887,\n 'epoch': 10.0}"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef predict_aspect(sentence, model, tokenizer, id2label):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    \n    # Tokenize và chuyển sang device\n    encoding = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1).squeeze().tolist()\n    \n    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().cpu())\n    labels = [id2label[pred] for pred in predictions]\n    \n    return list(zip(tokens, labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:50.803656Z","iopub.execute_input":"2025-09-18T12:32:50.804009Z","iopub.status.idle":"2025-09-18T12:32:50.812647Z","shell.execute_reply.started":"2025-09-18T12:32:50.803980Z","shell.execute_reply":"2025-09-18T12:32:50.811983Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"sentence = \"The battery life of this laptop is amazing.\"\nresult = predict_aspect(sentence, model, tokenizer, id2label)\n\nfor token, label in result:\n    print(f\"{token}\\t{label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:50.813680Z","iopub.execute_input":"2025-09-18T12:32:50.814027Z","iopub.status.idle":"2025-09-18T12:32:50.863301Z","shell.execute_reply.started":"2025-09-18T12:32:50.814008Z","shell.execute_reply":"2025-09-18T12:32:50.862764Z"}},"outputs":[{"name":"stdout","text":"[CLS]\tO\nthe\tO\nbattery\tB-ASP\nlife\tI-ASP\nof\tO\nthis\tO\nlaptop\tO\nis\tO\namazing\tO\n.\tO\n[SEP]\tO\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"sentence = \"The battery life is great but the screen is dull and the keyboard feels cheap.\"\nresult = predict_aspect(sentence, model, tokenizer, id2label)\n\nfor token, label in result:\n    print(f\"{token}\\t{label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:50.863973Z","iopub.execute_input":"2025-09-18T12:32:50.864179Z","iopub.status.idle":"2025-09-18T12:32:50.880514Z","shell.execute_reply.started":"2025-09-18T12:32:50.864162Z","shell.execute_reply":"2025-09-18T12:32:50.880014Z"}},"outputs":[{"name":"stdout","text":"[CLS]\tO\nthe\tO\nbattery\tB-ASP\nlife\tI-ASP\nis\tO\ngreat\tO\nbut\tO\nthe\tO\nscreen\tB-ASP\nis\tO\ndull\tO\nand\tO\nthe\tO\nkeyboard\tB-ASP\nfeels\tO\ncheap\tO\n.\tO\n[SEP]\tO\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## Lưu ","metadata":{}},{"cell_type":"code","source":"save_path = \"./bert_aspect_model_saved\"\n\nmodel.save_pretrained(save_path)\n\ntokenizer.save_pretrained(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:50.881184Z","iopub.execute_input":"2025-09-18T12:32:50.881421Z","iopub.status.idle":"2025-09-18T12:32:51.848040Z","shell.execute_reply.started":"2025-09-18T12:32:50.881399Z","shell.execute_reply":"2025-09-18T12:32:51.847264Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"('./bert_aspect_model_saved/tokenizer_config.json',\n './bert_aspect_model_saved/special_tokens_map.json',\n './bert_aspect_model_saved/vocab.txt',\n './bert_aspect_model_saved/added_tokens.json',\n './bert_aspect_model_saved/tokenizer.json')"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(save_path)\ntokenizer = AutoTokenizer.from_pretrained(save_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:51.848872Z","iopub.execute_input":"2025-09-18T12:32:51.849090Z","iopub.status.idle":"2025-09-18T12:32:51.959304Z","shell.execute_reply.started":"2025-09-18T12:32:51.849073Z","shell.execute_reply":"2025-09-18T12:32:51.958562Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"# Đánh giá khía cạnh ","metadata":{}},{"cell_type":"markdown","source":"## Tiền Xữ lí ","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(path_train)\ndf_test = pd.read_csv(path_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:51.960298Z","iopub.execute_input":"2025-09-18T12:32:51.960495Z","iopub.status.idle":"2025-09-18T12:32:51.975888Z","shell.execute_reply.started":"2025-09-18T12:32:51.960479Z","shell.execute_reply":"2025-09-18T12:32:51.975241Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:51.976617Z","iopub.execute_input":"2025-09-18T12:32:51.976817Z","iopub.status.idle":"2025-09-18T12:32:51.984522Z","shell.execute_reply.started":"2025-09-18T12:32:51.976802Z","shell.execute_reply":"2025-09-18T12:32:51.984001Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"     id                                           Sentence     Aspect Term  \\\n0  2339  I charge it at night and skip taking the cord ...            cord   \n1  2339  I charge it at night and skip taking the cord ...    battery life   \n2  1316  The tech guy then said the service center does...  service center   \n3  1316  The tech guy then said the service center does...    \"sales\" team   \n4  1316  The tech guy then said the service center does...        tech guy   \n\n   polarity  from   to  \n0   neutral    41   45  \n1  positive    74   86  \n2  negative    27   41  \n3  negative   109  121  \n4   neutral     4   12  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Sentence</th>\n      <th>Aspect Term</th>\n      <th>polarity</th>\n      <th>from</th>\n      <th>to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>neutral</td>\n      <td>41</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2339</td>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>positive</td>\n      <td>74</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>negative</td>\n      <td>27</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>\"sales\" team</td>\n      <td>negative</td>\n      <td>109</td>\n      <td>121</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1316</td>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>neutral</td>\n      <td>4</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"df_train_sent = df_train[['Sentence', 'Aspect Term', 'polarity']].copy()\ndf_test_sent = df_test[['Sentence', 'Aspect Term', 'polarity']].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:51.985236Z","iopub.execute_input":"2025-09-18T12:32:51.985854Z","iopub.status.idle":"2025-09-18T12:32:51.998566Z","shell.execute_reply.started":"2025-09-18T12:32:51.985830Z","shell.execute_reply":"2025-09-18T12:32:51.998041Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"label2id = {\"negative\":0, \"neutral\":1, \"positive\":2}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:51.999228Z","iopub.execute_input":"2025-09-18T12:32:51.999412Z","iopub.status.idle":"2025-09-18T12:32:52.010872Z","shell.execute_reply.started":"2025-09-18T12:32:51.999397Z","shell.execute_reply":"2025-09-18T12:32:52.010244Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"id2label = {v:k for k,v in label2id.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.011524Z","iopub.execute_input":"2025-09-18T12:32:52.011713Z","iopub.status.idle":"2025-09-18T12:32:52.023495Z","shell.execute_reply.started":"2025-09-18T12:32:52.011691Z","shell.execute_reply":"2025-09-18T12:32:52.022944Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"df_train_sent['label'] = df_train_sent['polarity'].map(label2id)\ndf_test_sent['label'] = df_test_sent['polarity'].map(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.024149Z","iopub.execute_input":"2025-09-18T12:32:52.024334Z","iopub.status.idle":"2025-09-18T12:32:52.037763Z","shell.execute_reply.started":"2025-09-18T12:32:52.024320Z","shell.execute_reply":"2025-09-18T12:32:52.037205Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"df_train_sent.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.038362Z","iopub.execute_input":"2025-09-18T12:32:52.038551Z","iopub.status.idle":"2025-09-18T12:32:52.055063Z","shell.execute_reply.started":"2025-09-18T12:32:52.038537Z","shell.execute_reply":"2025-09-18T12:32:52.054448Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                                            Sentence     Aspect Term  \\\n0  I charge it at night and skip taking the cord ...            cord   \n1  I charge it at night and skip taking the cord ...    battery life   \n2  The tech guy then said the service center does...  service center   \n3  The tech guy then said the service center does...    \"sales\" team   \n4  The tech guy then said the service center does...        tech guy   \n\n   polarity  label  \n0   neutral    1.0  \n1  positive    2.0  \n2  negative    0.0  \n3  negative    0.0  \n4   neutral    1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Aspect Term</th>\n      <th>polarity</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>neutral</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>positive</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>negative</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>\"sales\" team</td>\n      <td>negative</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>neutral</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"print(df_train_sent['label'].isnull().sum())\nprint(df_test_sent['label'].isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.055802Z","iopub.execute_input":"2025-09-18T12:32:52.056084Z","iopub.status.idle":"2025-09-18T12:32:52.072439Z","shell.execute_reply.started":"2025-09-18T12:32:52.056058Z","shell.execute_reply":"2025-09-18T12:32:52.071843Z"}},"outputs":[{"name":"stdout","text":"45\n0\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"df_train_sent = df_train_sent.dropna(subset=['label'])\ndf_test_sent = df_test_sent.dropna(subset=['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.073129Z","iopub.execute_input":"2025-09-18T12:32:52.073309Z","iopub.status.idle":"2025-09-18T12:32:52.090333Z","shell.execute_reply.started":"2025-09-18T12:32:52.073294Z","shell.execute_reply":"2025-09-18T12:32:52.089785Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"df_train_sent.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.091129Z","iopub.execute_input":"2025-09-18T12:32:52.091381Z","iopub.status.idle":"2025-09-18T12:32:52.107828Z","shell.execute_reply.started":"2025-09-18T12:32:52.091353Z","shell.execute_reply":"2025-09-18T12:32:52.107259Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"                                            Sentence     Aspect Term  \\\n0  I charge it at night and skip taking the cord ...            cord   \n1  I charge it at night and skip taking the cord ...    battery life   \n2  The tech guy then said the service center does...  service center   \n3  The tech guy then said the service center does...    \"sales\" team   \n4  The tech guy then said the service center does...        tech guy   \n\n   polarity  label  \n0   neutral    1.0  \n1  positive    2.0  \n2  negative    0.0  \n3  negative    0.0  \n4   neutral    1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Aspect Term</th>\n      <th>polarity</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>cord</td>\n      <td>neutral</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I charge it at night and skip taking the cord ...</td>\n      <td>battery life</td>\n      <td>positive</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>service center</td>\n      <td>negative</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>\"sales\" team</td>\n      <td>negative</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The tech guy then said the service center does...</td>\n      <td>tech guy</td>\n      <td>neutral</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"df_train_sent['label'] = df_train_sent['label'].astype(int)\ndf_test_sent['label'] = df_test_sent['label'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.108547Z","iopub.execute_input":"2025-09-18T12:32:52.108837Z","iopub.status.idle":"2025-09-18T12:32:52.122356Z","shell.execute_reply.started":"2025-09-18T12:32:52.108815Z","shell.execute_reply":"2025-09-18T12:32:52.121781Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"label_counts = df_train_sent['label'].value_counts()\nprint(label_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.122904Z","iopub.execute_input":"2025-09-18T12:32:52.123081Z","iopub.status.idle":"2025-09-18T12:32:52.140268Z","shell.execute_reply.started":"2025-09-18T12:32:52.123067Z","shell.execute_reply":"2025-09-18T12:32:52.139582Z"}},"outputs":[{"name":"stdout","text":"label\n2    987\n0    866\n1    460\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"dataset_train = Dataset.from_pandas(df_train_sent[['Sentence','Aspect Term','label']])\ndataset_test = Dataset.from_pandas(df_test_sent[['Sentence','Aspect Term','label']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.141099Z","iopub.execute_input":"2025-09-18T12:32:52.141308Z","iopub.status.idle":"2025-09-18T12:32:52.185375Z","shell.execute_reply.started":"2025-09-18T12:32:52.141294Z","shell.execute_reply":"2025-09-18T12:32:52.184875Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.185962Z","iopub.execute_input":"2025-09-18T12:32:52.186140Z","iopub.status.idle":"2025-09-18T12:32:52.538326Z","shell.execute_reply.started":"2025-09-18T12:32:52.186126Z","shell.execute_reply":"2025-09-18T12:32:52.537772Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"def tokenize_fn(batch):\n    return tokenizer(batch['Aspect Term'], batch['Sentence'], \n                     truncation=True, padding='max_length', max_length=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.539135Z","iopub.execute_input":"2025-09-18T12:32:52.539339Z","iopub.status.idle":"2025-09-18T12:32:52.543480Z","shell.execute_reply.started":"2025-09-18T12:32:52.539323Z","shell.execute_reply":"2025-09-18T12:32:52.542893Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"train_dataset = dataset_train.map(tokenize_fn, batched=True)\ntest_dataset = dataset_test.map(tokenize_fn, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.544243Z","iopub.execute_input":"2025-09-18T12:32:52.544468Z","iopub.status.idle":"2025-09-18T12:32:52.896493Z","shell.execute_reply.started":"2025-09-18T12:32:52.544451Z","shell.execute_reply":"2025-09-18T12:32:52.895771Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2313 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bc3e43c8edc418eafa27c04445c7686"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/49 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99a4820ca7d243b7b0d30d1b48b522e5"}},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"print(train_dataset['label'].count(None))\nprint(test_dataset['label'].count(None))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.897304Z","iopub.execute_input":"2025-09-18T12:32:52.897478Z","iopub.status.idle":"2025-09-18T12:32:52.902698Z","shell.execute_reply.started":"2025-09-18T12:32:52.897464Z","shell.execute_reply":"2025-09-18T12:32:52.902085Z"}},"outputs":[{"name":"stdout","text":"0\n0\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.903344Z","iopub.execute_input":"2025-09-18T12:32:52.903518Z","iopub.status.idle":"2025-09-18T12:32:52.917029Z","shell.execute_reply.started":"2025-09-18T12:32:52.903495Z","shell.execute_reply":"2025-09-18T12:32:52.916471Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Sentence', 'Aspect Term', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 2313\n})"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"def convert_label_to_int(batch):\n    batch['label'] = int(batch['label']) \n    return batch\n\ntrain_dataset = train_dataset.map(convert_label_to_int)\ntest_dataset = test_dataset.map(convert_label_to_int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:52.917808Z","iopub.execute_input":"2025-09-18T12:32:52.918082Z","iopub.status.idle":"2025-09-18T12:32:53.125674Z","shell.execute_reply.started":"2025-09-18T12:32:52.918031Z","shell.execute_reply":"2025-09-18T12:32:53.124955Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2313 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"752af5d75a75421d91db736c6d4e6195"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/49 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd0f23ffb520494e9686b0090ef8ad73"}},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"print(train_dataset['Sentence'][0])\nprint(train_dataset['Aspect Term'][0])\nprint(train_dataset['label'][0])\nprint(id2label[train_dataset['label'][0]])\ntokens = tokenizer.convert_ids_to_tokens(train_dataset['input_ids'][0])\n\ntokens_no_pad = [t for t, id_ in zip(tokens, train_dataset['input_ids'][0]) if id_ != tokenizer.pad_token_id]\n\nprint(tokens_no_pad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:53.126562Z","iopub.execute_input":"2025-09-18T12:32:53.126757Z","iopub.status.idle":"2025-09-18T12:32:53.358322Z","shell.execute_reply.started":"2025-09-18T12:32:53.126722Z","shell.execute_reply":"2025-09-18T12:32:53.357555Z"}},"outputs":[{"name":"stdout","text":"I charge it at night and skip taking the cord with me because of the good battery life.\ncord\n1\nneutral\n['[CLS]', 'cord', '[SEP]', 'i', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.', '[SEP]']\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nnum_labels = 3\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:53.359145Z","iopub.execute_input":"2025-09-18T12:32:53.359346Z","iopub.status.idle":"2025-09-18T12:32:53.597215Z","shell.execute_reply.started":"2025-09-18T12:32:53.359329Z","shell.execute_reply":"2025-09-18T12:32:53.596708Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:53.597952Z","iopub.execute_input":"2025-09-18T12:32:53.598144Z","iopub.status.idle":"2025-09-18T12:32:53.601844Z","shell.execute_reply.started":"2025-09-18T12:32:53.598129Z","shell.execute_reply":"2025-09-18T12:32:53.601014Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./bert_sentiment_model\",\n    num_train_epochs=10,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100, \n    eval_steps=100,              \n    save_total_limit=2,\n    save_steps=100,\n    report_to=\"none\",\n    disable_tqdm=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:53.602856Z","iopub.execute_input":"2025-09-18T12:32:53.603026Z","iopub.status.idle":"2025-09-18T12:32:53.637853Z","shell.execute_reply.started":"2025-09-18T12:32:53.603011Z","shell.execute_reply":"2025-09-18T12:32:53.637350Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"! pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:32:53.638493Z","iopub.execute_input":"2025-09-18T12:32:53.638705Z","iopub.status.idle":"2025-09-18T12:33:01.173245Z","shell.execute_reply.started":"2025-09-18T12:32:53.638681Z","shell.execute_reply":"2025-09-18T12:33:01.172474Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"import numpy as np\nimport evaluate  # mới\n\nmetric = evaluate.load(\"accuracy\")\n\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n    return metric.compute(predictions=preds, references=p.label_ids)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:33:01.174231Z","iopub.execute_input":"2025-09-18T12:33:01.174441Z","iopub.status.idle":"2025-09-18T12:33:02.120420Z","shell.execute_reply.started":"2025-09-18T12:33:01.174418Z","shell.execute_reply":"2025-09-18T12:33:02.119892Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7deeeb7b52c04d7995308f7ff92e8fea"}},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:33:02.121186Z","iopub.execute_input":"2025-09-18T12:33:02.121448Z","iopub.status.idle":"2025-09-18T12:33:02.345652Z","shell.execute_reply.started":"2025-09-18T12:33:02.121424Z","shell.execute_reply":"2025-09-18T12:33:02.345102Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2862702860.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:33:02.346629Z","iopub.execute_input":"2025-09-18T12:33:02.346921Z","iopub.status.idle":"2025-09-18T12:38:11.774094Z","shell.execute_reply.started":"2025-09-18T12:33:02.346896Z","shell.execute_reply":"2025-09-18T12:38:11.773342Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='730' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [730/730 05:08, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.671600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.374500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.226900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.104900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.088800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.042500</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.029300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=730, training_loss=0.2120430154343174, metrics={'train_runtime': 308.8223, 'train_samples_per_second': 74.897, 'train_steps_per_second': 2.364, 'total_flos': 1521453338012160.0, 'train_loss': 0.2120430154343174, 'epoch': 10.0})"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"trainer.evaluate(eval_dataset=train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:11.774867Z","iopub.execute_input":"2025-09-18T12:38:11.775162Z","iopub.status.idle":"2025-09-18T12:38:20.074301Z","shell.execute_reply.started":"2025-09-18T12:38:11.775136Z","shell.execute_reply":"2025-09-18T12:38:20.073745Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='75' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [73/73 00:08]\n    </div>\n    "},"metadata":{}},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.018919624388217926,\n 'eval_accuracy': 0.9922178988326849,\n 'eval_runtime': 8.2899,\n 'eval_samples_per_second': 279.014,\n 'eval_steps_per_second': 8.806,\n 'epoch': 10.0}"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"trainer.evaluate(eval_dataset=test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.074983Z","iopub.execute_input":"2025-09-18T12:38:20.075185Z","iopub.status.idle":"2025-09-18T12:38:20.272274Z","shell.execute_reply.started":"2025-09-18T12:38:20.075168Z","shell.execute_reply":"2025-09-18T12:38:20.271505Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.10492423176765442,\n 'eval_accuracy': 0.9795918367346939,\n 'eval_runtime': 0.1887,\n 'eval_samples_per_second': 259.704,\n 'eval_steps_per_second': 10.6,\n 'epoch': 10.0}"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import classification_report\n\ndef evaluate_model(trainer, test_dataset, id2label):\n    \"\"\"\n    trainer: HuggingFace Trainer đã train xong\n    test_dataset: HF Dataset dạng torch\n    id2label: dict mapping {0:'negative',1:'neutral',2:'positive'}\n    \"\"\"\n    model = trainer.model\n    model.eval()\n    \n    input_ids = torch.tensor(test_dataset['input_ids'])\n    attention_mask = torch.tensor(test_dataset['attention_mask'])\n    labels = torch.tensor(test_dataset['label'])\n    \n    device = next(model.parameters()).device\n    \n    preds = []\n    true_labels = []\n    \n    with torch.no_grad():\n        for i in range(len(input_ids)):\n            inputs = {\n                'input_ids': input_ids[i].unsqueeze(0).to(device),\n                'attention_mask': attention_mask[i].unsqueeze(0).to(device)\n            }\n            outputs = model(**inputs)\n            logits = outputs.logits\n            pred_id = torch.argmax(logits, dim=-1).item()\n            \n            preds.append(pred_id)\n            true_labels.append(labels[i].item() if torch.is_tensor(labels[i]) else labels[i])\n    \n    true_labels_str = [id2label[l] for l in true_labels]\n    preds_str = [id2label[p] for p in preds]\n    \n    report = classification_report(true_labels_str, preds_str, digits=4)\n    print(report)\n    \n    return report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.273118Z","iopub.execute_input":"2025-09-18T12:38:20.273922Z","iopub.status.idle":"2025-09-18T12:38:20.280119Z","shell.execute_reply.started":"2025-09-18T12:38:20.273902Z","shell.execute_reply":"2025-09-18T12:38:20.279490Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"id2label = {0:'negative', 1:'neutral', 2:'positive'}\nreport = evaluate_model(trainer, test_dataset, id2label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.280715Z","iopub.execute_input":"2025-09-18T12:38:20.280941Z","iopub.status.idle":"2025-09-18T12:38:20.740213Z","shell.execute_reply.started":"2025-09-18T12:38:20.280925Z","shell.execute_reply":"2025-09-18T12:38:20.739557Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    negative     1.0000    0.9375    0.9677        16\n     neutral     1.0000    1.0000    1.0000         4\n    positive     0.9667    1.0000    0.9831        29\n\n    accuracy                         0.9796        49\n   macro avg     0.9889    0.9792    0.9836        49\nweighted avg     0.9803    0.9796    0.9794        49\n\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef predict_aspect_sentiment(aspect, sentence, tokenizer, model, max_length=128):\n    \"\"\"\n    aspect: str, từ/cụm từ aspect\n    sentence: str, câu chứa aspect\n    tokenizer: BERT tokenizer\n    model: trained AutoModelForSequenceClassification\n    id2label: dict mapping {0: 'negative', 1: 'neutral', 2: 'positive'}\n    \"\"\"\n    model.eval()\n    \n    inputs = tokenizer(\n        aspect,\n        sentence,\n        truncation=True,\n        padding='max_length',\n        max_length=max_length,\n        return_tensors='pt'  \n    )\n\n    device = next(model.parameters()).device\n    inputs = {k:v.to(device) for k,v in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits  # [1, 3]\n        pred_id = torch.argmax(logits, dim=-1).item() \n    \n    return pred_id\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.740949Z","iopub.execute_input":"2025-09-18T12:38:20.741150Z","iopub.status.idle":"2025-09-18T12:38:20.746338Z","shell.execute_reply.started":"2025-09-18T12:38:20.741132Z","shell.execute_reply":"2025-09-18T12:38:20.745774Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"id2label = {0:'negative', 1:'neutral', 2:'positive'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.747082Z","iopub.execute_input":"2025-09-18T12:38:20.747637Z","iopub.status.idle":"2025-09-18T12:38:20.762966Z","shell.execute_reply.started":"2025-09-18T12:38:20.747619Z","shell.execute_reply":"2025-09-18T12:38:20.762404Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"aspect = \"battery life\"\nsentence = \"I love the battery life of this laptop, it lasts all day.\"\npred = predict_aspect_sentiment(aspect, sentence, tokenizer, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.763621Z","iopub.execute_input":"2025-09-18T12:38:20.763864Z","iopub.status.idle":"2025-09-18T12:38:20.785424Z","shell.execute_reply.started":"2025-09-18T12:38:20.763838Z","shell.execute_reply":"2025-09-18T12:38:20.784967Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"print(id2label[pred])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.786276Z","iopub.execute_input":"2025-09-18T12:38:20.786458Z","iopub.status.idle":"2025-09-18T12:38:20.790059Z","shell.execute_reply.started":"2025-09-18T12:38:20.786439Z","shell.execute_reply":"2025-09-18T12:38:20.789461Z"}},"outputs":[{"name":"stdout","text":"positive\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"aspect = \"battery life\"\nsentence = \"I have to charge the battery twice a day, which is really annoying and disappointing.\"\npred = predict_aspect_sentiment(aspect, sentence, tokenizer, model)\nprint(id2label[pred])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.790680Z","iopub.execute_input":"2025-09-18T12:38:20.791384Z","iopub.status.idle":"2025-09-18T12:38:20.814930Z","shell.execute_reply.started":"2025-09-18T12:38:20.791363Z","shell.execute_reply":"2025-09-18T12:38:20.814203Z"}},"outputs":[{"name":"stdout","text":"negative\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"## Lưu","metadata":{}},{"cell_type":"code","source":"save_path = \"./bert_sentiment_model_saved\"\n\nmodel.save_pretrained(save_path)\n\ntokenizer.save_pretrained(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:38:20.815641Z","iopub.execute_input":"2025-09-18T12:38:20.815843Z","iopub.status.idle":"2025-09-18T12:38:21.687814Z","shell.execute_reply.started":"2025-09-18T12:38:20.815827Z","shell.execute_reply":"2025-09-18T12:38:21.687222Z"}},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"('./bert_sentiment_model_saved/tokenizer_config.json',\n './bert_sentiment_model_saved/special_tokens_map.json',\n './bert_sentiment_model_saved/vocab.txt',\n './bert_sentiment_model_saved/added_tokens.json',\n './bert_sentiment_model_saved/tokenizer.json')"},"metadata":{}}],"execution_count":79},{"cell_type":"markdown","source":"# Tạo DEMO ","metadata":{}},{"cell_type":"code","source":"save_path = \"./bert_aspect_model_saved\"\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\n\nmodel_aspect = AutoModelForTokenClassification.from_pretrained(save_path)\ntokenizer_aspect = AutoTokenizer.from_pretrained(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:18.735335Z","iopub.execute_input":"2025-09-18T12:52:18.735603Z","iopub.status.idle":"2025-09-18T12:52:18.865524Z","shell.execute_reply.started":"2025-09-18T12:52:18.735580Z","shell.execute_reply":"2025-09-18T12:52:18.864784Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"save_path = \"./bert_sentiment_model_saved\"\nfrom transformers import AutoModelForSequenceClassification\nmodel_sentiment = AutoModelForSequenceClassification.from_pretrained(save_path)\ntokenizer_sentiment = AutoTokenizer.from_pretrained(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:19.687794Z","iopub.execute_input":"2025-09-18T12:52:19.688471Z","iopub.status.idle":"2025-09-18T12:52:19.811962Z","shell.execute_reply.started":"2025-09-18T12:52:19.688438Z","shell.execute_reply":"2025-09-18T12:52:19.811133Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"import torch\n\ndef predict_aspect(sentence, model, tokenizer):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    \n    encoding = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1).squeeze().tolist()\n    \n    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().cpu())\n    \n    return list(zip(tokens, predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:20.727071Z","iopub.execute_input":"2025-09-18T12:52:20.727603Z","iopub.status.idle":"2025-09-18T12:52:20.733276Z","shell.execute_reply.started":"2025-09-18T12:52:20.727578Z","shell.execute_reply":"2025-09-18T12:52:20.732591Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"# Example usage\nsentence = \"The battery life of this laptop is amazing.\"\nresult = predict_aspect(sentence, model_aspect, tokenizer_aspect)\n\nfor token, label in result:\n    print(f\"{token}\\t{label}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:23.021417Z","iopub.execute_input":"2025-09-18T12:52:23.022355Z","iopub.status.idle":"2025-09-18T12:52:23.187172Z","shell.execute_reply.started":"2025-09-18T12:52:23.022326Z","shell.execute_reply":"2025-09-18T12:52:23.186386Z"}},"outputs":[{"name":"stdout","text":"[CLS]\t0\nthe\t0\nbattery\t1\nlife\t2\nof\t0\nthis\t0\nlaptop\t0\nis\t0\namazing\t0\n.\t0\n[SEP]\t0\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"import torch\n\ndef predict_aspect_sentiment(aspect, sentence, tokenizer, model, max_length=128):\n    \"\"\"\n    aspect: str, từ/cụm từ aspect\n    sentence: str, câu chứa aspect\n    tokenizer: BERT tokenizer\n    model: trained AutoModelForSequenceClassification\n    {0: 'negative', 1: 'neutral', 2: 'positive'}\n    \"\"\"\n    model.eval()\n    \n    inputs = tokenizer(\n        aspect,\n        sentence,\n        truncation=True,\n        padding='max_length',\n        max_length=max_length,\n        return_tensors='pt'  \n    )\n\n    device = next(model.parameters()).device\n    inputs = {k:v.to(device) for k,v in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits  \n        pred_id = torch.argmax(logits, dim=-1).item() \n    \n    return pred_id\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:26.538986Z","iopub.execute_input":"2025-09-18T12:52:26.539586Z","iopub.status.idle":"2025-09-18T12:52:26.545330Z","shell.execute_reply.started":"2025-09-18T12:52:26.539555Z","shell.execute_reply":"2025-09-18T12:52:26.544536Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"aspect = \"battery life\"\nsentence = \"I have to charge the battery twice a day, which is really annoying and disappointing.\"\npred = predict_aspect_sentiment(aspect, sentence, tokenizer_sentiment, model_sentiment)\nprint(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:28.564445Z","iopub.execute_input":"2025-09-18T12:52:28.564721Z","iopub.status.idle":"2025-09-18T12:52:28.773225Z","shell.execute_reply.started":"2025-09-18T12:52:28.564701Z","shell.execute_reply":"2025-09-18T12:52:28.772385Z"}},"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"import gradio as gr\nimport torch\nimport re\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification\n\naspect_model_path = \"./bert_aspect_model_saved\"\nsentiment_model_path = \"./bert_sentiment_model_saved\"\n\nmodel_aspect = AutoModelForTokenClassification.from_pretrained(aspect_model_path)\ntokenizer_aspect = AutoTokenizer.from_pretrained(aspect_model_path)\n\nmodel_sentiment = AutoModelForSequenceClassification.from_pretrained(sentiment_model_path)\ntokenizer_sentiment = AutoTokenizer.from_pretrained(sentiment_model_path)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_aspect.to(device)\nmodel_sentiment.to(device)\n\n# Aspect prediction\ndef predict_aspect(sentence):\n    model_aspect.eval()\n    encoding = tokenizer_aspect(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model_aspect(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1).squeeze().tolist()\n    \n    tokens = tokenizer_aspect.convert_ids_to_tokens(input_ids.squeeze().cpu())\n    return list(zip(tokens, predictions))\n\n# Sentiment prediction\ndef predict_aspect_sentiment(aspect, sentence):\n    model_sentiment.eval()\n    inputs = tokenizer_sentiment(aspect, sentence, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n    inputs = {k:v.to(device) for k,v in inputs.items()}\n    with torch.no_grad():\n        outputs = model_sentiment(**inputs)\n        logits = outputs.logits\n        pred_id = torch.argmax(logits, dim=-1).item()\n    return pred_id\n\ndef clean_token(token):\n    if token in [\"[CLS]\", \"[SEP]\"]:\n        return \"\"\n    \n    if token.startswith(\"##\"):\n        return token[2:]\n    return token\n\ndef highlight_text(text):\n    sentences = re.split(r'(?<=[.!?;]) +', text)\n    highlighted_paragraph = \"\"\n    \n    for sentence in sentences:\n        token_preds = predict_aspect(sentence)\n        highlighted_sentence = \"\"\n        i = 0\n        while i < len(token_preds):\n            token, label = token_preds[i]\n            token = clean_token(token)\n            if not token:\n                i += 1\n                continue\n\n            if label != 0:\n                aspect_tokens = [token]\n                j = i + 1\n                while j < len(token_preds) and token_preds[j][1] != 0:\n                    t, l = token_preds[j]\n                    t = clean_token(t)\n                    if t: aspect_tokens.append(t)\n                    j += 1\n                aspect_text = \" \".join(aspect_tokens)\n                \n                sentiment = predict_aspect_sentiment(aspect_text, sentence)\n                color = \"red\" if sentiment == 0 else \"orange\" if sentiment == 1 else \"green\"\n                \n                highlighted_sentence += f'<span style=\"color:{color}; font-weight:bold\">{aspect_text}</span> '\n                i = j\n            else:\n                highlighted_sentence += token + \" \"\n                i += 1\n        highlighted_paragraph += highlighted_sentence.strip() + \" \"\n    \n    return highlighted_paragraph.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:30.275231Z","iopub.execute_input":"2025-09-18T12:52:30.275500Z","iopub.status.idle":"2025-09-18T12:52:30.830683Z","shell.execute_reply.started":"2025-09-18T12:52:30.275478Z","shell.execute_reply":"2025-09-18T12:52:30.829943Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"\n# Gradio interface\niface = gr.Interface(\n    fn=highlight_text,\n    inputs=gr.Textbox(lines=5, placeholder=\"Nhập đoạn văn của bạn ở đây...\"),\n    outputs=gr.HTML(),\n    title=\"ABSA Highlight\",\n    description=\"Nhập một đoạn văn, các khía cạnh sẽ được tô màu theo sentiment (red=negative, orange=neutral, green=positive)\"\n)\n\niface.launch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:52:35.851233Z","iopub.execute_input":"2025-09-18T12:52:35.851504Z","iopub.status.idle":"2025-09-18T12:52:36.590434Z","shell.execute_reply.started":"2025-09-18T12:52:35.851485Z","shell.execute_reply":"2025-09-18T12:52:36.589785Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7861\nIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://96ed1ea217ef09d37e.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://96ed1ea217ef09d37e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":96,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}